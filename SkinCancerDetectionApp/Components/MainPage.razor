@page "/"

@using DetectionService.Interfaces
@using DetectionService.Models
@using Microsoft.ML.OnnxRuntime.Tensors
@using SkinCancerDetectionApp.Services.ImageTransformService.Interfaces
@implements IAsyncDisposable

@inject IJSRuntime JS
@inject NavigationManager NavigationManager
@inject IDetectionService DetectionService
@inject IImageTransformService ImageTransformService

<div class="page">
    @if (_lastError is not null)
    {
        <p>Could not start video: @_lastError</p>

        if (HasReloaded == true)
        {
            <p>You may need to open the settings app to enable camera access for this app</p>
        }

        <button @onclick="Reload">Reload</button>
    }
    else
    {
        <video @ref="_videoReference" id="videoFeed">The current WebView does not support video.</video>
        <canvas class="d-none" id="currentFrame" width=@_width height=@_height />
        @if (_buttonVisibility != ButtonVisibility.None)
        {
            <div class="floating-btns">
                @if (_buttonVisibility == ButtonVisibility.Both)
                {
                    <button class="floating-btn btn-danger" @onclick="ResumeCameraFeed">Cancel</button>
                    <button class="floating-btn btn-success" @onclick="ProcessFrame">Infer</button>
                }
                else
                {
                    <button class="floating-btn btn-danger" @onclick="ResumeCameraFeed">Reset</button>
                }
            </div>
        }
        else
        {
            <button class="capture-btn" @onclick="PauseCameraFeed"></button>
        }
    }
</div>

@code {
    private ElementReference? _videoReference;
    private string? _lastError;
    private int _width = 320;
    private int _height = 320;
    private ButtonVisibility _buttonVisibility = ButtonVisibility.None;

    enum ButtonVisibility
    {
        None,
        Both,
        One
    }

    [Parameter]
    [SupplyParameterFromQuery(Name = "reloaded")]
    public bool? HasReloaded { get; set; }

    protected override async Task OnAfterRenderAsync(bool firstRender)
    {
        if (firstRender)
        {
            _lastError = await JS.InvokeAsync<string?>("startCameraFeed", _videoReference);
            StateHasChanged();
        }
    }

    private void Reload()
    {
        var reloadedUri = NavigationManager.GetUriWithQueryParameter("reloaded", true);
        NavigationManager.NavigateTo(reloadedUri, true);
    }

    private async Task PauseCameraFeed()
    {
        _buttonVisibility = ButtonVisibility.Both;
        await JS.InvokeVoidAsync("pauseCameraFeed", _videoReference);
    }

    private async Task ResumeCameraFeed()
    {
        _buttonVisibility = ButtonVisibility.None;
        await JS.InvokeVoidAsync("resumeCameraFeed", _videoReference);
    }

    private async Task ProcessFrame()
    {
        _buttonVisibility = ButtonVisibility.One;
        await JS.InvokeVoidAsync(
            "processFrame", "videoFeed", "currentFrame", _width, _height, DotNetObjectReference.Create(this));
    }

    [JSInvokable]
    public void ProcessImage(string imageString)
    {
        byte[] jpegArray = Convert.FromBase64String(imageString);
        Tensor<float> imageTensor = ImageTransformService.JpegArrayToTensor(jpegArray);
        IImageTransform transform = ImageTransformService.GetImageTransform();
        Tensor<float> transformedImageTensor = transform.Apply(imageTensor);

        // TODO: Implement inference, show the bounding box and the predicted class on the screen.
        DetectionOutput? output = DetectionService.RunInference(transformedImageTensor);
    }

    async ValueTask IAsyncDisposable.DisposeAsync()
    {
        await JS.InvokeVoidAsync("stopCameraFeed", _videoReference);
    }
}